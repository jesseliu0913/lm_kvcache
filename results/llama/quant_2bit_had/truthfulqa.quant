nohup: ignoring input
2024-07-02:22:10:36,795 INFO     [__main__.py:223] Verbosity set to INFO
2024-07-02:22:10:36,795 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.
2024-07-02:22:10:40,899 INFO     [__main__.py:307] Selected Tasks: ['truthfulqa']
2024-07-02:22:10:40,899 INFO     [__main__.py:308] Loading selected tasks...
2024-07-02:22:10:40,902 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-02:22:10:41,053 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-07-02:22:10:41,053 INFO     [llama_qt.py:167] Using device 'cuda'
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.56s/it]
2024-07-02:22:10:46,744 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage
2024-07-02:22:10:51,433 INFO     [task.py:386] Building contexts for truthfulqa_gen on rank 0...
  0%|          | 0/817 [00:00<?, ?it/s] 14%|█▍        | 116/817 [00:00<00:00, 1155.93it/s] 33%|███▎      | 272/817 [00:00<00:00, 1391.45it/s] 53%|█████▎    | 432/817 [00:00<00:00, 1485.64it/s] 72%|███████▏  | 591/817 [00:00<00:00, 1523.10it/s] 92%|█████████▏| 749/817 [00:00<00:00, 1542.98it/s]100%|██████████| 817/817 [00:00<00:00, 1497.83it/s]
2024-07-02:22:10:52,052 INFO     [task.py:386] Building contexts for truthfulqa_mc1 on rank 0...
  0%|          | 0/817 [00:00<?, ?it/s] 11%|█▏        | 93/817 [00:00<00:00, 926.33it/s] 23%|██▎       | 186/817 [00:00<00:00, 927.60it/s] 34%|███▍      | 280/817 [00:00<00:00, 930.32it/s] 46%|████▌     | 374/817 [00:00<00:00, 931.40it/s] 57%|█████▋    | 468/817 [00:00<00:00, 930.49it/s] 69%|██████▉   | 563/817 [00:00<00:00, 933.07it/s] 81%|████████  | 658/817 [00:00<00:00, 936.65it/s] 92%|█████████▏| 753/817 [00:00<00:00, 938.28it/s]100%|██████████| 817/817 [00:00<00:00, 934.61it/s]
2024-07-02:22:10:52,972 INFO     [task.py:386] Building contexts for truthfulqa_mc2 on rank 0...
  0%|          | 0/817 [00:00<?, ?it/s] 11%|█▏        | 93/817 [00:00<00:00, 921.17it/s] 23%|██▎       | 186/817 [00:00<00:00, 924.90it/s] 34%|███▍      | 279/817 [00:00<00:00, 923.03it/s] 46%|████▌     | 372/817 [00:00<00:00, 909.00it/s] 57%|█████▋    | 464/817 [00:00<00:00, 912.77it/s] 68%|██████▊   | 557/817 [00:00<00:00, 917.92it/s] 80%|███████▉  | 650/817 [00:00<00:00, 921.59it/s] 91%|█████████ | 743/817 [00:00<00:00, 923.50it/s]100%|██████████| 817/817 [00:00<00:00, 920.81it/s]
2024-07-02:22:10:53,905 INFO     [evaluator.py:365] Running generate_until requests
Running generate_until requests:   0%|          | 0/817 [00:00<?, ?it/s]/scratch0/zx22/zijie/miniconda3/envs/llama/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/scratch0/zx22/zijie/miniconda3/envs/llama/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running generate_until requests:   0%|          | 1/817 [00:20<4:41:31, 20.70s/it]Running generate_until requests:   0%|          | 3/817 [00:32<2:14:23,  9.91s/it]Running generate_until requests:   1%|          | 5/817 [00:33<1:06:15,  4.90s/it]Running generate_until requests:   1%|          | 7/817 [00:33<39:09,  2.90s/it]  Running generate_until requests:   1%|          | 9/817 [00:45<55:21,  4.11s/it]Running generate_until requests:   1%|▏         | 11/817 [00:46<36:19,  2.70s/it]Running generate_until requests:   2%|▏         | 13/817 [00:58<50:54,  3.80s/it]Running generate_until requests:   2%|▏         | 15/817 [01:10<1:00:44,  4.54s/it]Running generate_until requests:   2%|▏         | 17/817 [01:22<1:07:11,  5.04s/it]Running generate_until requests:   2%|▏         | 19/817 [01:22<47:14,  3.55s/it]  Running generate_until requests:   3%|▎         | 21/817 [01:35<57:32,  4.34s/it]Running generate_until requests:   3%|▎         | 23/817 [01:36<43:20,  3.28s/it]Running generate_until requests:   3%|▎         | 25/817 [01:37<30:28,  2.31s/it]Running generate_until requests:   3%|▎         | 27/817 [01:37<21:55,  1.67s/it]Running generate_until requests:   4%|▎         | 29/817 [01:37<15:53,  1.21s/it]Running generate_until requests:   4%|▍         | 31/817 [01:38<11:42,  1.12it/s]Running generate_until requests:   4%|▍         | 33/817 [01:39<10:11,  1.28it/s]Running generate_until requests:   4%|▍         | 35/817 [01:51<30:33,  2.34s/it]Running generate_until requests:   5%|▍         | 37/817 [01:51<22:23,  1.72s/it]Running generate_until requests:   5%|▍         | 39/817 [02:03<38:56,  3.00s/it]Running generate_until requests:   5%|▌         | 41/817 [02:04<28:03,  2.17s/it]Running generate_until requests:   5%|▌         | 43/817 [02:04<20:11,  1.57s/it]Running generate_until requests:   6%|▌         | 45/817 [02:04<14:58,  1.16s/it]Running generate_until requests:   6%|▌         | 47/817 [02:05<11:26,  1.12it/s]Running generate_until requests:   6%|▌         | 49/817 [02:17<31:28,  2.46s/it]Running generate_until requests:   6%|▌         | 51/817 [02:17<22:18,  1.75s/it]Running generate_until requests:   6%|▋         | 53/817 [02:17<15:54,  1.25s/it]Running generate_until requests:   7%|▋         | 55/817 [02:18<11:48,  1.08it/s]Running generate_until requests:   7%|▋         | 57/817 [02:18<08:55,  1.42it/s]Running generate_until requests:   7%|▋         | 59/817 [02:18<06:33,  1.93it/s]Running generate_until requests:   7%|▋         | 61/817 [02:19<05:26,  2.32it/s]Running generate_until requests:   8%|▊         | 63/817 [02:19<04:28,  2.80it/s]Running generate_until requests:   8%|▊         | 65/817 [02:20<03:59,  3.14it/s]Running generate_until requests:   8%|▊         | 67/817 [02:20<03:27,  3.61it/s]Running generate_until requests:   8%|▊         | 69/817 [02:20<03:00,  4.15it/s]Running generate_until requests:   9%|▊         | 71/817 [02:20<02:25,  5.12it/s]Running generate_until requests:   9%|▉         | 73/817 [02:21<02:22,  5.24it/s]Running generate_until requests:   9%|▉         | 75/817 [02:21<01:58,  6.25it/s]Running generate_until requests:   9%|▉         | 77/817 [02:21<02:03,  6.00it/s]Running generate_until requests:  10%|▉         | 79/817 [02:22<01:55,  6.37it/s]Running generate_until requests:  10%|▉         | 81/817 [02:22<01:40,  7.34it/s]Running generate_until requests:  10%|█         | 83/817 [02:22<01:49,  6.69it/s]Running generate_until requests:  10%|█         | 85/817 [02:22<01:50,  6.60it/s]Running generate_until requests:  11%|█         | 87/817 [02:23<02:53,  4.22it/s]