nohup: ignoring input
2024-06-25:23:48:51,946 INFO     [__main__.py:223] Verbosity set to INFO
2024-06-25:23:48:51,946 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.
2024-06-25:23:48:56,017 INFO     [__main__.py:307] Selected Tasks: ['coqa']
2024-06-25:23:48:56,017 INFO     [__main__.py:308] Loading selected tasks...
2024-06-25:23:48:56,018 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-25:23:48:56,096 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-06-25:23:48:56,096 INFO     [falcon_quant.py:166] Using device 'cuda'
2024-06-25:23:48:56,566 WARNING  [logging.py:328] 
WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.

The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:  50%|█████     | 1/2 [03:18<03:18, 198.35s/it]Downloading shards: 100%|██████████| 2/2 [04:55<00:00, 138.81s/it]Downloading shards: 100%|██████████| 2/2 [04:55<00:00, 147.74s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/scratch0/zx22/zijie/miniconda3/envs/llama/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.81s/it]
2024-06-25:23:54:03,921 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage
2024-06-25:23:54:06,425 INFO     [task.py:386] Building contexts for coqa on rank 0...
  0%|          | 0/500 [00:00<?, ?it/s]100%|██████████| 500/500 [00:00<00:00, 60730.68it/s]
2024-06-25:23:54:06,575 INFO     [evaluator.py:365] Running generate_until requests
Running generate_until requests:   0%|          | 0/500 [00:00<?, ?it/s]Running generate_until requests:   0%|          | 1/500 [00:30<4:12:03, 30.31s/it]Running generate_until requests:   2%|▏         | 9/500 [00:33<22:58,  2.81s/it]  Running generate_until requests:   3%|▎         | 17/500 [00:36<11:25,  1.42s/it]Running generate_until requests:   5%|▌         | 25/500 [00:38<07:10,  1.10it/s]Running generate_until requests:   7%|▋         | 33/500 [00:41<05:16,  1.48it/s]Running generate_until requests:   8%|▊         | 41/500 [00:43<04:07,  1.85it/s]Running generate_until requests:  10%|▉         | 49/500 [00:46<03:31,  2.13it/s]Running generate_until requests:  11%|█▏        | 57/500 [00:48<02:56,  2.51it/s]Running generate_until requests:  13%|█▎        | 65/500 [00:50<02:32,  2.86it/s]Running generate_until requests:  15%|█▍        | 73/500 [00:52<02:19,  3.06it/s]Running generate_until requests:  16%|█▌        | 81/500 [00:54<02:10,  3.22it/s]Running generate_until requests:  18%|█▊        | 89/500 [00:56<01:58,  3.47it/s]Running generate_until requests:  19%|█▉        | 97/500 [00:59<02:07,  3.16it/s]Running generate_until requests:  21%|██        | 105/500 [01:01<01:53,  3.47it/s]Running generate_until requests:  23%|██▎       | 113/500 [01:03<01:43,  3.75it/s]Running generate_until requests:  24%|██▍       | 121/500 [01:04<01:37,  3.91it/s]Running generate_until requests:  26%|██▌       | 129/500 [01:06<01:32,  3.99it/s]Running generate_until requests:  27%|██▋       | 137/500 [01:08<01:29,  4.04it/s]Running generate_until requests:  29%|██▉       | 145/500 [01:10<01:28,  3.99it/s]Running generate_until requests:  31%|███       | 153/500 [01:12<01:26,  3.99it/s]Running generate_until requests:  32%|███▏      | 161/500 [01:14<01:27,  3.88it/s]Running generate_until requests:  34%|███▍      | 169/500 [01:16<01:24,  3.91it/s]Running generate_until requests:  35%|███▌      | 177/500 [01:19<01:27,  3.68it/s]Running generate_until requests:  37%|███▋      | 185/500 [01:21<01:23,  3.75it/s]Running generate_until requests:  39%|███▊      | 193/500 [01:23<01:25,  3.61it/s]Running generate_until requests:  40%|████      | 201/500 [01:25<01:18,  3.79it/s]Running generate_until requests:  42%|████▏     | 209/500 [01:27<01:11,  4.08it/s]Running generate_until requests:  43%|████▎     | 217/500 [01:30<01:16,  3.68it/s]Running generate_until requests:  45%|████▌     | 225/500 [01:31<01:11,  3.86it/s]Running generate_until requests:  47%|████▋     | 233/500 [01:33<01:07,  3.98it/s]Running generate_until requests:  48%|████▊     | 241/500 [01:35<01:02,  4.15it/s]Running generate_until requests:  50%|████▉     | 249/500 [01:37<00:58,  4.26it/s]Running generate_until requests:  51%|█████▏    | 257/500 [01:39<00:56,  4.31it/s]Running generate_until requests:  53%|█████▎    | 265/500 [01:40<00:53,  4.41it/s]Running generate_until requests:  55%|█████▍    | 273/500 [01:42<00:52,  4.35it/s]Running generate_until requests:  56%|█████▌    | 281/500 [01:44<00:49,  4.42it/s]Running generate_until requests:  58%|█████▊    | 289/500 [01:46<00:47,  4.42it/s]Running generate_until requests:  59%|█████▉    | 297/500 [01:47<00:45,  4.44it/s]Running generate_until requests:  61%|██████    | 305/500 [01:53<01:08,  2.85it/s]Running generate_until requests:  63%|██████▎   | 313/500 [01:54<00:58,  3.21it/s]Running generate_until requests:  64%|██████▍   | 321/500 [01:56<00:49,  3.61it/s]Running generate_until requests:  66%|██████▌   | 329/500 [01:58<00:43,  3.95it/s]Running generate_until requests:  67%|██████▋   | 337/500 [01:59<00:38,  4.18it/s]Running generate_until requests:  69%|██████▉   | 345/500 [02:01<00:37,  4.10it/s]Running generate_until requests:  71%|███████   | 353/500 [02:03<00:33,  4.44it/s]Running generate_until requests:  72%|███████▏  | 361/500 [02:04<00:29,  4.77it/s]Running generate_until requests:  74%|███████▍  | 369/500 [02:06<00:28,  4.63it/s]Running generate_until requests:  75%|███████▌  | 377/500 [02:09<00:31,  3.86it/s]Running generate_until requests:  77%|███████▋  | 385/500 [02:10<00:26,  4.32it/s]Running generate_until requests:  79%|███████▊  | 393/500 [02:12<00:23,  4.54it/s]Running generate_until requests:  80%|████████  | 401/500 [02:14<00:23,  4.23it/s]Running generate_until requests:  82%|████████▏ | 409/500 [02:16<00:20,  4.42it/s]Running generate_until requests:  83%|████████▎ | 417/500 [02:17<00:18,  4.53it/s]Running generate_until requests:  85%|████████▌ | 425/500 [02:18<00:15,  4.97it/s]Running generate_until requests:  87%|████████▋ | 433/500 [02:20<00:12,  5.33it/s]Running generate_until requests:  88%|████████▊ | 441/500 [02:21<00:10,  5.50it/s]Running generate_until requests:  90%|████████▉ | 449/500 [02:23<00:10,  5.01it/s]Running generate_until requests:  91%|█████████▏| 457/500 [02:24<00:07,  5.38it/s]Running generate_until requests:  93%|█████████▎| 465/500 [02:25<00:06,  5.62it/s]Running generate_until requests:  95%|█████████▍| 473/500 [02:28<00:05,  4.63it/s]Running generate_until requests:  96%|█████████▌| 481/500 [02:29<00:03,  4.94it/s]Running generate_until requests:  98%|█████████▊| 489/500 [02:30<00:02,  5.30it/s]Running generate_until requests:  99%|█████████▉| 497/500 [02:31<00:00,  6.42it/s]Running generate_until requests: 100%|██████████| 500/500 [02:31<00:00,  3.30it/s]
Passed argument batch_size = auto. Detecting largest batch size
Determined Largest batch size: 8
quant_falcon (pretrained=tiiuae/falcon-7b;8,dtype=bfloat16,low_cpu_mem_usage=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto
|Tasks|Version|Filter|n-shot|Metric|Value |   |Stderr|
|-----|------:|------|------|------|-----:|---|-----:|
|coqa |      3|none  |None  |em    |0.5993|±  |0.0193|
|     |       |none  |None  |f1    |0.7245|±  |0.0159|

