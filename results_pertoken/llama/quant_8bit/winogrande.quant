nohup: ignoring input
2024-06-19 23:55:28.203716: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-19 23:55:29.036796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2024-06-19 23:55:31,710] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-06-19:23:55:33,144 INFO     [__main__.py:223] Verbosity set to INFO
2024-06-19:23:55:33,144 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.
2024-06-19:23:55:38,103 INFO     [__main__.py:307] Selected Tasks: ['winogrande']
2024-06-19:23:55:38,103 INFO     [__main__.py:308] Loading selected tasks...
2024-06-19:23:55:38,105 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-19:23:55:38,111 INFO     [llama_quant.py:163] Using device 'cuda'
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2024-06-19:23:56:17,696 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage
2024-06-19:23:56:20,175 INFO     [task.py:386] Building contexts for winogrande on rank 0...
  0%|          | 0/1267 [00:00<?, ?it/s]100%|██████████| 1267/1267 [00:00<00:00, 99894.42it/s]
2024-06-19:23:56:20,226 INFO     [evaluator.py:365] Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/2534 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/2534 [00:02<2:02:38,  2.90s/it]Running loglikelihood requests:   3%|▎         | 65/2534 [00:03<01:28, 27.97it/s] Running loglikelihood requests:   5%|▌         | 129/2534 [00:03<00:41, 57.85it/s]Running loglikelihood requests:   8%|▊         | 193/2534 [00:03<00:26, 89.08it/s]Running loglikelihood requests:  10%|█         | 257/2534 [00:03<00:19, 119.50it/s]Running loglikelihood requests:  13%|█▎        | 321/2534 [00:04<00:14, 148.91it/s]Running loglikelihood requests:  15%|█▌        | 385/2534 [00:04<00:12, 175.46it/s]Running loglikelihood requests:  18%|█▊        | 449/2534 [00:04<00:10, 196.49it/s]Running loglikelihood requests:  20%|██        | 513/2534 [00:04<00:09, 215.95it/s]Running loglikelihood requests:  23%|██▎       | 577/2534 [00:05<00:08, 231.69it/s]Running loglikelihood requests:  25%|██▌       | 641/2534 [00:05<00:07, 243.67it/s]Running loglikelihood requests:  28%|██▊       | 705/2534 [00:05<00:07, 251.88it/s]Running loglikelihood requests:  30%|███       | 769/2534 [00:05<00:06, 263.53it/s]Running loglikelihood requests:  33%|███▎      | 833/2534 [00:06<00:06, 272.81it/s]Running loglikelihood requests:  35%|███▌      | 897/2534 [00:06<00:05, 278.62it/s]Running loglikelihood requests:  38%|███▊      | 961/2534 [00:06<00:05, 284.05it/s]Running loglikelihood requests:  40%|████      | 1025/2534 [00:06<00:05, 287.06it/s]Running loglikelihood requests:  43%|████▎     | 1089/2534 [00:06<00:04, 290.07it/s]Running loglikelihood requests:  46%|████▌     | 1153/2534 [00:07<00:04, 295.17it/s]Running loglikelihood requests:  48%|████▊     | 1217/2534 [00:07<00:04, 297.25it/s]Running loglikelihood requests:  51%|█████     | 1281/2534 [00:07<00:04, 299.10it/s]Running loglikelihood requests:  53%|█████▎    | 1345/2534 [00:07<00:03, 302.15it/s]Running loglikelihood requests:  56%|█████▌    | 1409/2534 [00:07<00:03, 303.13it/s]Running loglikelihood requests:  58%|█████▊    | 1473/2534 [00:08<00:03, 304.78it/s]Running loglikelihood requests:  61%|██████    | 1537/2534 [00:08<00:03, 310.53it/s]Running loglikelihood requests:  63%|██████▎   | 1601/2534 [00:08<00:02, 314.42it/s]Running loglikelihood requests:  66%|██████▌   | 1665/2534 [00:08<00:02, 317.30it/s]Running loglikelihood requests:  68%|██████▊   | 1729/2534 [00:08<00:02, 319.09it/s]Running loglikelihood requests:  71%|███████   | 1793/2534 [00:09<00:02, 321.80it/s]Running loglikelihood requests:  73%|███████▎  | 1857/2534 [00:09<00:02, 323.46it/s]Running loglikelihood requests:  76%|███████▌  | 1921/2534 [00:09<00:01, 324.67it/s]Running loglikelihood requests:  78%|███████▊  | 1985/2534 [00:09<00:01, 324.89it/s]Running loglikelihood requests:  81%|████████  | 2049/2534 [00:09<00:01, 333.86it/s]Running loglikelihood requests:  83%|████████▎ | 2113/2534 [00:10<00:01, 340.44it/s]Running loglikelihood requests:  86%|████████▌ | 2177/2534 [00:10<00:01, 345.13it/s]Running loglikelihood requests:  88%|████████▊ | 2241/2534 [00:10<00:00, 348.08it/s]Running loglikelihood requests:  91%|█████████ | 2305/2534 [00:10<00:00, 350.27it/s]Running loglikelihood requests:  93%|█████████▎| 2369/2534 [00:10<00:00, 355.94it/s]Running loglikelihood requests:  96%|█████████▌| 2433/2534 [00:10<00:00, 358.06it/s]Running loglikelihood requests:  99%|█████████▊| 2497/2534 [00:11<00:00, 390.70it/s]Running loglikelihood requests: 100%|██████████| 2534/2534 [00:11<00:00, 227.62it/s]
Passed argument batch_size = auto:1. Detecting largest batch size
Determined largest batch size: 64
qh_llama (pretrained=meta-llama/Llama-2-7b-hf,dtype=float16,low_cpu_mem_usage=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto (64)
|  Tasks   |Version|Filter|n-shot|Metric|Value|   |Stderr|
|----------|------:|------|------|------|----:|---|-----:|
|winogrande|      1|none  |None  |acc   |0.693|±  | 0.013|

