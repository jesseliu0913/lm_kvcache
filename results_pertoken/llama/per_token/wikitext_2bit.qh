nohup: ignoring input
2024-07-02:22:05:02,866 INFO     [__main__.py:223] Verbosity set to INFO
2024-07-02:22:05:02,866 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.
2024-07-02:22:05:06,892 INFO     [__main__.py:307] Selected Tasks: ['wikitext']
2024-07-02:22:05:06,892 INFO     [__main__.py:308] Loading selected tasks...
2024-07-02:22:05:06,894 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-02:22:05:07,057 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-07-02:22:05:07,057 INFO     [llama_qt.py:167] Using device 'cuda'
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.49s/it]
2024-07-02:22:05:12,567 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage
2024-07-02:22:05:12,569 WARNING  [task.py:740] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-07-02:22:05:12,569 WARNING  [task.py:752] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-07-02:22:05:12,569 WARNING  [task.py:740] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-07-02:22:05:12,569 WARNING  [task.py:752] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-07-02:22:05:12,569 WARNING  [task.py:740] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-07-02:22:05:12,569 WARNING  [task.py:752] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
Repo card metadata block was not found. Setting CardData to empty.
2024-07-02:22:05:13,208 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.
2024-07-02:22:05:13,376 INFO     [task.py:386] Building contexts for wikitext on rank 0...
  0%|          | 0/62 [00:00<?, ?it/s] 65%|██████▍   | 40/62 [00:00<00:00, 395.39it/s]100%|██████████| 62/62 [00:00<00:00, 475.44it/s]
2024-07-02:22:05:13,512 INFO     [evaluator.py:365] Running loglikelihood_rolling requests
Passed argument batch_size = auto. Detecting largest batch size
Determined Largest batch size: 2
  0%|          | 0/62 [00:00<?, ?it/s]  2%|▏         | 1/62 [00:00<00:27,  2.26it/s]  3%|▎         | 2/62 [00:02<01:41,  1.68s/it]  5%|▍         | 3/62 [00:04<01:21,  1.39s/it]  6%|▋         | 4/62 [00:07<02:16,  2.35s/it]  8%|▊         | 5/62 [00:08<01:42,  1.80s/it] 10%|▉         | 6/62 [00:09<01:26,  1.54s/it] 11%|█▏        | 7/62 [00:14<02:29,  2.71s/it] 13%|█▎        | 8/62 [00:15<01:57,  2.19s/it] 15%|█▍        | 9/62 [00:21<02:44,  3.11s/it] 16%|█▌        | 10/62 [00:21<02:02,  2.36s/it] 18%|█▊        | 11/62 [00:22<01:42,  2.02s/it] 19%|█▉        | 12/62 [00:26<02:08,  2.57s/it] 21%|██        | 13/62 [00:27<01:33,  1.91s/it] 23%|██▎       | 14/62 [00:28<01:17,  1.61s/it] 24%|██▍       | 15/62 [00:28<00:55,  1.19s/it] 26%|██▌       | 16/62 [00:29<00:47,  1.04s/it] 27%|██▋       | 17/62 [00:32<01:24,  1.89s/it] 29%|██▉       | 18/62 [00:33<01:03,  1.44s/it] 31%|███       | 19/62 [00:35<01:16,  1.78s/it] 32%|███▏      | 20/62 [00:38<01:24,  2.02s/it] 34%|███▍      | 21/62 [00:41<01:29,  2.19s/it] 35%|███▌      | 22/62 [00:41<01:06,  1.67s/it] 37%|███▋      | 23/62 [00:44<01:15,  1.94s/it] 39%|███▊      | 24/62 [00:49<01:50,  2.91s/it] 40%|████      | 25/62 [00:50<01:27,  2.35s/it] 42%|████▏     | 26/62 [00:54<01:41,  2.81s/it] 44%|████▎     | 27/62 [00:59<02:03,  3.52s/it] 45%|████▌     | 28/62 [00:59<01:28,  2.59s/it] 48%|████▊     | 30/62 [00:59<00:45,  1.43s/it] 50%|█████     | 31/62 [01:02<00:53,  1.72s/it] 52%|█████▏    | 32/62 [01:03<00:42,  1.43s/it] 53%|█████▎    | 33/62 [01:05<00:50,  1.74s/it] 55%|█████▍    | 34/62 [01:06<00:40,  1.44s/it] 56%|█████▋    | 35/62 [01:10<00:57,  2.13s/it] 58%|█████▊    | 36/62 [01:14<01:08,  2.64s/it] 60%|█████▉    | 37/62 [01:14<00:51,  2.06s/it] 61%|██████▏   | 38/62 [01:21<01:20,  3.36s/it] 63%|██████▎   | 39/62 [01:23<01:12,  3.13s/it] 65%|██████▍   | 40/62 [01:28<01:22,  3.74s/it] 66%|██████▌   | 41/62 [01:34<01:27,  4.17s/it] 68%|██████▊   | 42/62 [01:35<01:04,  3.24s/it] 69%|██████▉   | 43/62 [01:35<00:45,  2.39s/it] 71%|███████   | 44/62 [01:38<00:44,  2.45s/it] 73%|███████▎  | 45/62 [01:39<00:33,  1.98s/it] 74%|███████▍  | 46/62 [01:39<00:24,  1.51s/it] 76%|███████▌  | 47/62 [01:39<00:17,  1.19s/it] 77%|███████▋  | 48/62 [01:43<00:27,  1.99s/it] 79%|███████▉  | 49/62 [01:44<00:20,  1.55s/it] 81%|████████  | 50/62 [01:44<00:15,  1.25s/it] 82%|████████▏ | 51/62 [01:46<00:14,  1.28s/it] 84%|████████▍ | 52/62 [01:47<00:12,  1.25s/it] 85%|████████▌ | 53/62 [01:47<00:08,  1.00it/s] 87%|████████▋ | 54/62 [01:48<00:06,  1.22it/s] 89%|████████▊ | 55/62 [01:48<00:04,  1.45it/s] 90%|█████████ | 56/62 [01:48<00:03,  1.72it/s] 92%|█████████▏| 57/62 [01:52<00:07,  1.57s/it] 94%|█████████▎| 58/62 [01:53<00:04,  1.16s/it] 95%|█████████▌| 59/62 [01:55<00:04,  1.59s/it] 97%|█████████▋| 60/62 [01:58<00:03,  1.89s/it] 98%|█████████▊| 61/62 [02:00<00:02,  2.10s/it]100%|██████████| 62/62 [02:03<00:00,  2.24s/it]100%|██████████| 62/62 [02:03<00:00,  1.99s/it]
qt_llama (pretrained=meta-llama/Llama-2-7b-hf;2,dtype=float16,low_cpu_mem_usage=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto
| Tasks  |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|--------|------:|------|------|---------------|-----:|---|------|
|wikitext|      2|none  |None  |word_perplexity|8.7920|±  |N/A   |
|        |       |none  |None  |byte_perplexity|1.5016|±  |N/A   |
|        |       |none  |None  |bits_per_byte  |0.5865|±  |N/A   |

