nohup: ignoring input
2024-07-02:22:05:02,942 INFO     [__main__.py:223] Verbosity set to INFO
2024-07-02:22:05:02,942 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.
2024-07-02:22:05:07,012 INFO     [__main__.py:307] Selected Tasks: ['wikitext']
2024-07-02:22:05:07,012 INFO     [__main__.py:308] Loading selected tasks...
2024-07-02:22:05:07,013 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-07-02:22:05:07,150 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2024-07-02:22:05:07,150 INFO     [llama_quant.py:167] Using device 'cuda'
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.44s/it]
2024-07-02:22:05:12,574 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage
2024-07-02:22:05:12,576 WARNING  [task.py:740] [Task: wikitext] metric word_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-07-02:22:05:12,576 WARNING  [task.py:752] [Task: wikitext] metric word_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-07-02:22:05:12,576 WARNING  [task.py:740] [Task: wikitext] metric byte_perplexity is defined, but aggregation is not. using default aggregation=weighted_perplexity
2024-07-02:22:05:12,576 WARNING  [task.py:752] [Task: wikitext] metric byte_perplexity is defined, but higher_is_better is not. using default higher_is_better=False
2024-07-02:22:05:12,576 WARNING  [task.py:740] [Task: wikitext] metric bits_per_byte is defined, but aggregation is not. using default aggregation=bits_per_byte
2024-07-02:22:05:12,576 WARNING  [task.py:752] [Task: wikitext] metric bits_per_byte is defined, but higher_is_better is not. using default higher_is_better=False
Repo card metadata block was not found. Setting CardData to empty.
2024-07-02:22:05:13,223 WARNING  [repocard.py:107] Repo card metadata block was not found. Setting CardData to empty.
2024-07-02:22:05:13,274 INFO     [task.py:386] Building contexts for wikitext on rank 0...
  0%|          | 0/62 [00:00<?, ?it/s]100%|██████████| 62/62 [00:00<00:00, 758.64it/s]
2024-07-02:22:05:13,359 INFO     [evaluator.py:365] Running loglikelihood_rolling requests
Passed argument batch_size = auto. Detecting largest batch size
Determined Largest batch size: 2
  0%|          | 0/62 [00:00<?, ?it/s]  2%|▏         | 1/62 [00:00<00:26,  2.27it/s]  3%|▎         | 2/62 [00:02<01:40,  1.67s/it]  5%|▍         | 3/62 [00:03<01:21,  1.38s/it]  6%|▋         | 4/62 [00:07<02:15,  2.33s/it]  8%|▊         | 5/62 [00:08<01:41,  1.78s/it] 10%|▉         | 6/62 [00:09<01:25,  1.53s/it] 11%|█▏        | 7/62 [00:14<02:27,  2.69s/it] 13%|█▎        | 8/62 [00:15<01:56,  2.16s/it] 15%|█▍        | 9/62 [00:20<02:43,  3.08s/it] 16%|█▌        | 10/62 [00:21<02:01,  2.33s/it] 18%|█▊        | 11/62 [00:22<01:42,  2.00s/it] 19%|█▉        | 12/62 [00:26<02:07,  2.56s/it] 21%|██        | 13/62 [00:26<01:32,  1.89s/it] 23%|██▎       | 14/62 [00:27<01:17,  1.61s/it] 24%|██▍       | 15/62 [00:28<00:55,  1.18s/it] 26%|██▌       | 16/62 [00:28<00:47,  1.03s/it] 27%|██▋       | 17/62 [00:32<01:24,  1.87s/it] 29%|██▉       | 18/62 [00:33<01:03,  1.43s/it] 31%|███       | 19/62 [00:35<01:15,  1.77s/it] 32%|███▏      | 20/62 [00:38<01:24,  2.00s/it] 34%|███▍      | 21/62 [00:40<01:28,  2.16s/it] 35%|███▌      | 22/62 [00:41<01:06,  1.65s/it] 37%|███▋      | 23/62 [00:43<01:14,  1.92s/it] 39%|███▊      | 24/62 [00:48<01:49,  2.88s/it] 40%|████      | 25/62 [00:49<01:26,  2.33s/it] 42%|████▏     | 26/62 [00:53<01:40,  2.78s/it] 44%|████▎     | 27/62 [00:58<02:01,  3.48s/it] 45%|████▌     | 28/62 [00:59<01:27,  2.56s/it] 48%|████▊     | 30/62 [00:59<00:45,  1.41s/it] 50%|█████     | 31/62 [01:01<00:52,  1.70s/it] 52%|█████▏    | 32/62 [01:02<00:42,  1.41s/it] 53%|█████▎    | 33/62 [01:05<00:49,  1.72s/it] 55%|█████▍    | 34/62 [01:05<00:39,  1.42s/it] 56%|█████▋    | 35/62 [01:09<00:56,  2.11s/it] 58%|█████▊    | 36/62 [01:13<01:07,  2.61s/it] 60%|█████▉    | 37/62 [01:14<00:50,  2.03s/it] 61%|██████▏   | 38/62 [01:20<01:19,  3.32s/it] 63%|██████▎   | 39/62 [01:22<01:11,  3.09s/it] 65%|██████▍   | 40/62 [01:28<01:21,  3.69s/it] 66%|██████▌   | 41/62 [01:33<01:26,  4.11s/it] 68%|██████▊   | 42/62 [01:34<01:03,  3.20s/it] 69%|██████▉   | 43/62 [01:34<00:44,  2.36s/it] 71%|███████   | 44/62 [01:37<00:43,  2.42s/it] 73%|███████▎  | 45/62 [01:38<00:33,  1.95s/it] 74%|███████▍  | 46/62 [01:38<00:23,  1.49s/it] 76%|███████▌  | 47/62 [01:38<00:17,  1.17s/it] 77%|███████▋  | 48/62 [01:42<00:27,  1.97s/it] 79%|███████▉  | 49/62 [01:43<00:19,  1.53s/it] 81%|████████  | 50/62 [01:43<00:14,  1.24s/it] 82%|████████▏ | 51/62 [01:45<00:13,  1.26s/it] 84%|████████▍ | 52/62 [01:46<00:12,  1.24s/it] 85%|████████▌ | 53/62 [01:46<00:08,  1.01it/s] 87%|████████▋ | 54/62 [01:47<00:06,  1.23it/s] 89%|████████▊ | 55/62 [01:47<00:04,  1.47it/s] 90%|█████████ | 56/62 [01:47<00:03,  1.74it/s] 92%|█████████▏| 57/62 [01:51<00:07,  1.55s/it] 94%|█████████▎| 58/62 [01:51<00:04,  1.15s/it] 95%|█████████▌| 59/62 [01:54<00:04,  1.57s/it] 97%|█████████▋| 60/62 [01:56<00:03,  1.86s/it] 98%|█████████▊| 61/62 [01:59<00:02,  2.07s/it]100%|██████████| 62/62 [02:02<00:00,  2.21s/it]100%|██████████| 62/62 [02:02<00:00,  1.97s/it]
quant_llama (pretrained=meta-llama/Llama-2-7b-hf;2,dtype=float16,low_cpu_mem_usage=True,trust_remote_code=True), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto
| Tasks  |Version|Filter|n-shot|    Metric     |Value |   |Stderr|
|--------|------:|------|------|---------------|-----:|---|------|
|wikitext|      2|none  |None  |word_perplexity|8.7920|±  |N/A   |
|        |       |none  |None  |byte_perplexity|1.5016|±  |N/A   |
|        |       |none  |None  |bits_per_byte  |0.5865|±  |N/A   |

